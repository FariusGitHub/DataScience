{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "SOUP.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FariusGitHub/DataScience/blob/master/DS15BS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkH9vmqLJi7N",
        "outputId": "70ac74a1-f394-4514-b845-d7773b79c7d1"
      },
      "source": [
        "#BS4 ONLY, TESTING ON DS 1ST PAGE\n",
        "import bs4\n",
        "import requests\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "\n",
        "soup = bs4.BeautifulSoup(requests.get('https://ca.indeed.com/jobs?q=\\\n",
        "data+scientist&l=Toronto,+ON&start=0').text, 'lxml')\n",
        "\n",
        "DSsite=[]\n",
        "DSsoup=[]\n",
        "for i in tqdm(range(len(soup.select('.title')))):\n",
        "    jk =    str(soup.find_all(\"script\", text=re.compile(\"jobmap\"), type=\\\n",
        "          \"text/javascript\")[0]).split('\\n\\n')[i+3].split(\"]= {jk:'\")[1]\\\n",
        "          .split(\",cmpid:'\")[0].split(\"',efccid:\")[0]\n",
        "    fccid = str(soup.find_all(\"script\", text=re.compile(\"jobmap\"), type=\\\n",
        "          \"text/javascript\")[0]).split('\\n\\n')[i+3].split(\"]= {jk:'\")[1]\\\n",
        "          .split(\",cmpid:'\")[1].split(\"',num:'\")[0]\n",
        "    DSsite+=['http://ca.indeed.com/rc/clk?jk='+jk+'&fccid='+fccid+'&vjs=3']\n",
        "  # STORING SUBSOUP\n",
        "    DSsoup+=[bs4.BeautifulSoup(requests.get(DSsite[i]).text, 'lxml')]\n",
        "\n",
        "DSdesc=[]\n",
        "for i in range(len(soup.select('.title'))):\n",
        "    j = 0 if soup.select('.date')[i].text[:1].isalpha() \\\n",
        "    else int (soup.select('.date')[i].text[:2])\n",
        "    k = (datetime.today().date()-timedelta((j))).strftime(\"%x\")\n",
        "    DSdesc+=['<p>'.join(str(DSsoup[i].select(\".jobsearch-jobDescriptionText\")[0])\\\n",
        "          .split('</p>')).lstrip('<div class=\"jobsearch-jobDescriptionText\" id=\\\n",
        "          \"jobDescriptionText\"><p>')]\n",
        "    print(i+1,'\\n', \n",
        "   '>=30days' if j == 30 else k, '\\n',                                 # DATE\n",
        "   soup.select('.title')[i].a.get('title'), '\\n',                      # TITLE        \n",
        "   soup.select('.sjcl')[i](class_='company')[0].text.strip('\\n'), '\\n',# COMPANY\n",
        "   soup.select('.sjcl')[i](class_='recJobLoc')[0].get('data-rc-loc'), '\\n',# LOC      \n",
        "   soup.select('.summary')[i].text.strip('\\n'), '\\n',                  # SUMMARY      \n",
        "   DSsite[i], '\\n',                                                    # WEBSITE\n",
        "   DSdesc[i],  '\\n\\n'                                                  # DESC\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:16<00:00,  1.11s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 \n",
            " >=30days \n",
            " Data Scientist/Machine Learning Engineer \n",
            " Staffinity Inc. \n",
            " Toronto, ON \n",
            " Evaluating state-of-the-art statistical modeling and Machine Learning approaches using historical data.\n",
            "We offer competitive salaries and great bonuses and… \n",
            " http://ca.indeed.com/rc/clk?jk=63a9885a9063bbb1&fccid=640f182ba57686f6&vjs=3 \n",
            " About Staffinity Inc.<p><p>We are your trusted bilingual recruiting, short and long-term staffing service provider. Our primary goal has been matching sought-after employers with talented candidates. We are your source to get you in front of desirable employers who are now hiring in your area. Please visit us at https://staffinity.ca<p><p><b>Why Work With Us?</b><br/><b>We are awesome: We push the boundaries of new technology and are always trying to stay ahead of the curve</b><br/><b>We have a great team dynamic with a more client centered approach</b><br/><b>We offer competitive salaries and great bonuses and perks!</b><p><p>Staffinity is looking for an Data Scientist/Machine Learning Engineer for a permanent, full time position in Toronto ON. The work will be done primarily with R.<p><p>Responsibilities:<br/>Develop math models and algorithms<br/>Evaluating state-of-the-art statistical modeling and Machine Learning approaches using historical data<br/>Deploy models using .NET framework (C#)<br/>Data Analysis, Visualization and Modeling with large datasets<br/>Data Acquisition, Cleaning, and Transformation<p><p>Qualifications:<br/>Degree or Diploma in Computer Science, Software Engineering, or equivalent experience.<br/>5+ years .NET Development experience.<br/>Devops experience is a strong asset<br/>5+ years of experience as Software Developer, preferably using Microsoft .NET Framework (C# or VB.NET)<br/>5+ years of experience with statistical programming languages, R strongly preffered<br/>Betting or markets experience is a strong asset<p><p>Job Types: Full-time, Permanent<p><p>Salary: $80,000.00-$120,000.00 per year<p><p>Additional pay:<p><ul><li>Bonus Pay</li></ul><p>Benefits:<p><ul><li>Company Events</li><li>Dental Care</li><li>Extended Health Care</li><li>Flexible Schedule</li><li>On-site Parking</li><li>Paid Time Off</li><li>RRSP Match</li><li>Vision Care</li></ul><p>Schedule:<p><ul><li>8 Hour Shift</li><li>Day shift</li><li>Monday to Friday</li><li>No Weekends</li></ul><p>Experience:<p><ul><li>.NET: 2 years (Required)</li><li>AWS: 2 years (Required)</li><li>Machine Learning algorithms and Probabilistic Models: 2 years (Required)</li><li>R: 3 years (Required)</li><li>2 sided market: 2 years (Required)</li></ul><p>Work remotely:<p><ul><li>No</li></ul></div> \n",
            "\n",
            "\n",
            "2 \n",
            " 10/20/20 \n",
            " Data Scientist/ Analyst with Fraud Detection Systems and AI Toolkits experience \n",
            " Proex Inc \n",
            " Toronto, ON \n",
            " Strong business and data analysis skills.\n",
            "Experience in dealing with large anddiverse data assets, and in identifying thesuitability of specific data sets in… \n",
            " http://ca.indeed.com/rc/clk?jk=498a793d4439c7d8&fccid=13f782334b8ac5dd&vjs=3 \n",
            " RQ00120 - Task-Based I&amp;IT Consultant - Level 2<p>\n",
            "<p><b>Data Scientist/ Analyst - Leve2 with Fraud Detection Systems and AI experience</b><p>\n",
            "<p>86.00 days plus extensions<p>\n",
            "<p>Ministry of Health and long term care<p>\n",
            "<p>5700 Yonge Street, Toronto, ON, M2M 4K5<p><br/>\n",
            "<p><p>\n",
            "<p><b>Position will start as remote and transition to onsite when safe to do so with the remainder of the team<br/>\n",
            "</b><p><p><p><p><b>MUST HAVE SKILLS: FRAUD DETECTION, DATA SCIENCE, BUSINESS/ DATA ANALYSIS, GENERAL (see grid at end of job description)</b><p><br/>\n",
            "<p><p>\n",
            "<p><b>Role</b>:<br/>\n",
            "<p><p><p><p>OPS requires a resource to come in for the initial planning and implementation phase of the implementation of the fraud detection system. This resource will assist with the selection of the solution and consider various options including vendor selections for off the shelf, building in house, etc. Resource will identify what data is currently available and what OPS needs. They are looking for a resource with strong expertise in this area.<p><br/>\n",
            "<p><p>\n",
            "<p><b>Must haves:</b><p>\n",
            "<ul><li>Strong and recent experience in <b>end to end </b>implementation and operations of a fraud detections</li>\n",
            "<li>Resource needs to understand what it takes to put a fraud detection solution into production.</li>\n",
            "<li><b>Background in fraud detection and data science a MUST</b></li>\n",
            "<li>Ideal background in open source fraud solutions, claims based fraud detection and commercial product experience</li>\n",
            "<li>Experience with Python a strong asset</li>\n",
            "<li>Resource needs to have technical knowledge of fraud detection systems (not just someone who has used them in the past) and also strong communication and interpersonal skills</li>\n",
            "<li>Experience with drafting business requirements or business use cases specifically related to fraud detection services</li>\n",
            "<li><b>Familiar with various AI toolkits</b> (no specifics as one has not yet been selected)</li><br/>\n",
            "</ul>\n",
            "<p>\n",
            "<p><p><b>The required skills for the Data Scientist/Analyst L2 are:</b><p>\n",
            "<ul><li>Experience dealing with financial transactions in fraud detection techniques (ideally in a payper claim model)</li>\n",
            "<li>Familiarity with fraud detection technics (rule-based, statistical/predictive models, AI) andsoftware tools</li>\n",
            "<li>Strong business and data analysis skills</li>\n",
            "<li>Have solution designing experience in Fraud Detection platform setup including infrastructureand software</li>\n",
            "<li>Experience designing and building predictive models with both traditional data mining as wellas modern machine learning/AI algorithms</li>\n",
            "<li>Familiarity with one or more AI toolkits (ex.TensorFlow, Torch, Keras)</li>\n",
            "<li>Expertise in open-source data science tools (preferably python)</li>\n",
            "<li>Experience in operationalizing predictive models</li>\n",
            "<li>Communication and presentation skills</li>\n",
            "</ul><ul><li>Ideal resource would have experience with:</li>\n",
            "</ul><ul><li>Financial data related to health-related services</li>\n",
            "<li>Processing financial claims (insurance industry)</li>\n",
            "<li>Home grown and/or commercial solutions for fraud detection</li>\n",
            "</ul>\n",
            "<p>Deliverables<p>\n",
            "<div> <div><div><div><ul><li>Work with various business areas of the Ministry to support BIBA efforts in understandingand consolidating the Program/Business requirements for fraud/anomaly detection</li>\n",
            "<li>Perform detailed analysis and determine the suitability of data science methodologies andtools as well as propose potential technical solutions</li>\n",
            "<li>Understand short from long term business objectives and come up with a roadmap</li>\n",
            "<li>Review various datasets available in terms of their suitability, and where gaps are found,suggest what other data might be needed to resolve specific problems.</li>\n",
            "<li>Propose technical solutions which may include developed in-house as well as off-the-shelfcommercial products</li>\n",
            "<li>Develop benchmarking tests for comparing various solutions proposed by external vendors<br/>\n",
            "</li></ul></div></div><br/>\n",
            "<p><p><div><div><ul><li>Draft a Business Case proposal for a project to address Fraud Detection requirements forthe Ministry.</li></ul>\n",
            "<ul><li>Document the solutions proposed and organize workshops with business and IT teams asto ensure stakeholders support, educate and forge collaboration.</li></ul>\n",
            "<ul><li>Perform knowledge transfer for any solution proposed<br/>\n",
            "</li></ul></div></div><br/>\n",
            "<div><div><ul><li>Develop a proof of concept to illustrate the technical solutions proposed<br/>\n",
            "</li></ul></div></div><br/>\n",
            "<p><p><div><div><p>Fraud detection<p><br/>\n",
            "</div><div>\n",
            "<ul><li>Experience in dealing with financialtransactions including fraud detectiontechniques (ideally in a pay per claimmodel)</li></ul>\n",
            "<ul><li>Experience in designing/building/tuningfraud detection systems using custom buildand/or commercial products employingvarious methodologies (rule-based,predictive models, deep learning)</li></ul>\n",
            "<ul><li>Have solution designingexperience in Fraud Detectionplatform setup includinginfrastructure and software<br/>\n",
            "</li></ul></div><div><p>30<p><br/>\n",
            "</div></div></div></div><p><p>\n",
            "<p><p><div><div><div><div><p>Data Science<p><br/>\n",
            "</div><div>\n",
            "<ul><li>Expert proficiency in analytics and datascience with focus on building and tuningpredictive models using open-sourceand/or commercial tools</li></ul>\n",
            "<ul><li>Experience in collecting, cleansingtransforming data as to support effectivedecision-making process<br/>\n",
            "</li></ul></div><div><p>25<p><br/>\n",
            "</div></div><div>\n",
            "<div>\n",
            "<p>Business/Data analysis<p><br/>\n",
            "</div><div>\n",
            "<ul><li>Experience working with businesspeople as to understand businessprocesses and needs and create precisebusiness requirements</li></ul>\n",
            "<ul><li>Experience in dealing with large anddiverse data assets, and in identifying thesuitability of specific data sets in buildingpredictive models for specific problems</li></ul>\n",
            "<ul><li>Experience working with both technicaland non-technical people as to forgecollaboration and common understanding<br/>\n",
            "</li></ul></div><div><p>10<p><br/>\n",
            "</div></div><div>\n",
            "<div>\n",
            "<p>General<p><br/>\n",
            "</div><div>\n",
            "<ul><li>Critical thinking, analytical andproblem-solving skills</li></ul>\n",
            "<ul><li>Excellent verbal and writtencommunication skills.</li></ul>\n",
            "<ul><li>Strong consulting skills to engage withall stakeholders.</li></ul>\n",
            "<ul><li>Proven track record for building strongworking relationships</li></ul>\n",
            "<p>· Excellent customer service skills,including tact and diplomacy to ensureclient needs are managed effectively · Amotivated, flexible, creative team playerwith perseverance, excellent multi-taskingabilities and a proven track record formeeting strict deadlines<p><br/>\n",
            "</div></div><p><p><div><div>\n",
            "</div></div><br/>\n",
            "</div></div><div></div><p><br/>\n",
            "[alten-email email=heather@proex.ca]<p></div></div> \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: 'Just poste'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-7b4c66369c7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mDSdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' + day days ago'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Just poste'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHYtxxq7Ji7d",
        "outputId": "69fb660e-d791-4370-a440-59a9faec08b5"
      },
      "source": [
        "len(soup.select('.title'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtx0hxPLJi7s",
        "outputId": "9601eec4-8594-44a0-b6b4-faef0af3af10"
      },
      "source": [
        "import bs4\n",
        "import requests\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "\n",
        "soup = bs4.BeautifulSoup(requests.get('https://ca.indeed.com/jobs?q=\\\n",
        "data+scientist&l=Toronto,+ON&start=0').text, 'lxml')\n",
        "\n",
        "\n",
        "for i in range(len(soup.select('.title'))):\n",
        "    print(i+1, soup.select('.date')[i].text)\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Just posted\n",
            "2 30+ days ago\n",
            "3 Just posted\n",
            "4 Just posted\n",
            "5 Today\n",
            "6 3 days ago\n",
            "7 30+ days ago\n",
            "8 7 days ago\n",
            "9 25 days ago\n",
            "10 Today\n",
            "11 17 days ago\n",
            "12 18 days ago\n",
            "13 30+ days ago\n",
            "14 12 days ago\n",
            "15 30+ days ago\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJYXD8O3Ji73",
        "outputId": "5f6f6681-0eb2-491a-ec2f-5e96447625d4"
      },
      "source": [
        "for i in range(len(soup.select('.title'))):\n",
        "    j = 0 if soup.select('.date')[i].text[:1].isalpha() else int (soup.select('.date')[i].text[:2])\n",
        "    k = (datetime.today().date()-timedelta((j))).strftime(\"%x\")\n",
        "    print(k)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/27/20\n",
            "09/27/20\n",
            "10/27/20\n",
            "10/27/20\n",
            "10/27/20\n",
            "10/24/20\n",
            "09/27/20\n",
            "10/20/20\n",
            "10/02/20\n",
            "10/27/20\n",
            "10/10/20\n",
            "10/09/20\n",
            "09/27/20\n",
            "10/15/20\n",
            "09/27/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXUqLM8LJi8B",
        "outputId": "937763d5-6ed9-42ae-ded3-231ca5447da1"
      },
      "source": [
        "soup.select('.date')[0].text[:1].isalpha()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}