{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOUP2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8OJcX+R2YH/sLostMSO72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FariusGitHub/DataScience/blob/master/SOUP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcZqHxc-XFRm"
      },
      "source": [
        "import bs4\n",
        "import requests\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "\n",
        "# GETTING POSSIBLE LIST FROM INDEED MULTIPLE PAGES FOR TORONTO DATA SCIENTIST\n",
        "DSW1=[]; DST1=[]; DSS1= []; DSL1= []; DSC1=[]; DSD1=[]; DSE1=[]; DATE=[]\n",
        "soup = bs4.BeautifulSoup(requests.get('https://ca.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=25&l=toronto%2C+on&fromage=any&limit=50&sort=&psf=advsrch&from=advancedsearch').text, 'lxml')\n",
        "\n",
        "for l in tqdm(range(0,int(soup.find('div', id='searchCountPages').text.strip('\\n Page jobs').split(' of')[1])//50*50,50)):\n",
        "    start = l\n",
        "    soup = bs4.BeautifulSoup(requests.get('https://ca.indeed.com/jobs?q=data+\\\n",
        "            scientist&l=Toronto,+ON&start='+str(start)+'&limit=50').text, 'lxml')\n",
        "\n",
        " \n",
        "    jk=[]; fccid=[]; \n",
        "    for i in range(len(soup.select('.title'))):\n",
        "        j = 0 if soup.select('.date')[i].text.strip()[:2].isalpha() \\\n",
        "            else int(soup.select('.date')[i].text.strip()[:2])\n",
        "        k=(datetime.today().date()-timedelta((j))).strftime(\"%x\")\n",
        "        jk += [str(soup.find_all(\"script\", text=re.compile(\"jobmap\"), \\\n",
        "              type=\"text/javascript\")[0]).split('\\n\\n')[i+3]\\\n",
        "              .split(\"]= {jk:'\")[1].split(\",cmpid:'\")[0].split(\"',efccid:\")[0]]\n",
        "        fccid += [str(soup.find_all(\"script\", text=re.compile(\"jobmap\"), \\\n",
        "                type=\"text/javascript\")[0]).split('\\n\\n')[i+3]\\\n",
        "                .split(\"]= {jk:'\")[1].split(\",cmpid:'\")[1].split(\"',num:'\")[0]]\n",
        "        DSW1+=['http://ca.indeed.com/rc/clk?jk='+jk[i]+'&fccid='+fccid[i]+'&vjs=3'] #WEB\n",
        "        DST1+=[soup.select('.title')[i].a.get('title')]                             #TITLE\n",
        "        DSS1+=[soup.select('.summary')[i].text.strip('\\n')]                         #SUMMARY\n",
        "        DSL1+=[soup.select('.sjcl')[i](class_='recJobLoc')[0].get('data-rc-loc')]   #LOC\n",
        "        DSC1+=[soup.select('.sjcl')[i](class_='company')[0].text.strip('\\n')]       #COMPANY \n",
        "        DSD1+=['>=30days' if j == 30 else k]                                        #DURATION \n",
        "        DATE+=[date.today()]\n",
        "\n",
        "# GETTING JOB DESC FROM INDIVIDUAL JOB SITE ABOVE\n",
        "DSE1=[]\n",
        "print(len(DSW1))\n",
        "for i in tqdm(range(len(DSW1))):\n",
        "    try:\n",
        "        DSE1 += ['<p>'.join(str(bs4.BeautifulSoup(requests.get(DSW1[i])\\\n",
        "        .text, 'lxml').select(\".jobsearch-jobDescriptionText\")[0])\\\n",
        "        .split('</p>')).lstrip('<div class=\"jobsearch-jobDescriptionText\" id=\\\n",
        "              \"jobDescriptionText\"><p>')]\n",
        "    except Exception:\n",
        "        DSE1 += ['error during downloading']            #DESC\n",
        "\n",
        "# PREPARING REPORT AND OPEN EXCEL        \n",
        "df = pd.DataFrame(list(zip(DST1, DSC1, DSL1, DSS1, DSE1, DATE, DSD1, DSW1)),\n",
        "      columns =['Title', 'Company', 'Location', 'Summary', 'Description', 'Date', 'Duration', 'Link'])\n",
        "\n",
        "df.style.hide_index()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}